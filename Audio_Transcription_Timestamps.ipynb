{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Installs and Imports"
      ],
      "metadata": {
        "id": "mSrCM17zfIOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OCHb4BTEr34m"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!pip install openai\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "!pip install pydub\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key='your-key-here'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "mp3_files = []\n",
        "m4a_files = []\n",
        "best_of_files = []\n",
        "\n",
        "path = '/content/drive/My Drive/'\n",
        "\n",
        "for x in os.listdir(path):\n",
        "    if \"mp3\" in x:\n",
        "        mp3_files.append(x)\n",
        "    if \"m4a\" in x:\n",
        "        m4a_files.append(x)\n",
        "    if \"best-of\" in x:\n",
        "        best_of_files.append(x)\n",
        "\n",
        "for x in mp3_files:\n",
        "    print(x)\n",
        "print()\n",
        "\n",
        "for x in m4a_files:\n",
        "    print(x)\n",
        "print()\n",
        "\n",
        "for x in best_of_files:\n",
        "    print(x)\n",
        "print()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YzqEvBHBr-X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def combine_audio_segments(input_files, output_file):\n",
        "    # Create an empty AudioSegment to hold the combined audio\n",
        "    combined_audio = AudioSegment.empty()\n",
        "\n",
        "    # Iterate over each input file name\n",
        "    for file_name in input_files:\n",
        "        # Construct the full file path\n",
        "\n",
        "        # Load the input audio file\n",
        "        audio = AudioSegment.from_file(file_name)\n",
        "        # Append the audio from this file to the combined audio\n",
        "        combined_audio += audio\n",
        "\n",
        "    # Export the combined audio to a new file\n",
        "    combined_audio.export(output_file, format=\"wav\")"
      ],
      "metadata": {
        "id": "gFpjJ-HhT87i"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_files = best_of_files\n",
        "output_file = path+\"best-of-audio\"\n",
        "combine_audio_segments(input_files, output_file)"
      ],
      "metadata": {
        "id": "y9fwrr1yVLv8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def split_audio_by_chunks(file_name, input_file, output_dir, num_chunks):\n",
        "    # Load the audio file\n",
        "    audio = AudioSegment.from_file(input_file, format=\"m4a\")\n",
        "\n",
        "    # Calculate the size of each chunk\n",
        "    chunk_size = len(audio) // num_chunks\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Split the audio into chunks\n",
        "    for i in range(num_chunks):\n",
        "        start_byte = i * chunk_size\n",
        "        end_byte = min((i + 1) * chunk_size, len(audio))\n",
        "        chunk = audio[start_byte:end_byte]\n",
        "        output_file = output_dir+f\"{file_name}-chunk_{i}.wav\"\n",
        "        print(f\"output_file: {output_file}\")\n",
        "        chunk.export(output_file, format=\"wav\")\n",
        "\n",
        "    print(f\"Audio file split into {num_chunks} chunks.\")"
      ],
      "metadata": {
        "id": "FE6ImYjts584"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# audio_file = client.files.retrieve(\"file-PxvfyVEfVwTaKTUneWO793GP\")\n",
        "\n",
        "for x in m4a_files:\n",
        "    file_name = x\n",
        "    print(f\"file_name: {file_name}\")\n",
        "    input_file = path+file_name   # Provide your input audio file\n",
        "    print(f\"input_file: {input_file}\")\n",
        "    chunks_dir = path+file_name+\"-chunks/\"      # Provide the directory where chunks will be saved\n",
        "    print(f\"chunks_dir: {chunks_dir}\")\n",
        "    max_size_bytes = 26214400 # Maximum size of each chunk in bytes (e.g., 10 MB)\n",
        "    file_size = os.path.getsize(path+file_name)\n",
        "    print(f\"file_size: {file_size}\")\n",
        "    num_chunks = (int(file_size/max_size_bytes)+2)*4\n",
        "    print(f\"num_chunks: {num_chunks}\")\n",
        "    print()\n",
        "    split_audio_by_chunks(file_name, input_file, chunks_dir, num_chunks)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B0eM8fwgsC6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to check if content is inappropriate\n",
        "def is_content_inappropriate(input_text):\n",
        "    # Call OpenAI's content moderation model\n",
        "    moderation = client.moderations.create(input=input_text)\n",
        "\n",
        "    # Extracting the CategoryScores object from the moderation response\n",
        "    category_scores = moderation.results[0].category_scores\n",
        "\n",
        "    # Extracting all categories from the CategoryScores object\n",
        "    categories = category_scores.__dict__\n",
        "\n",
        "    # Extracting the category with the highest score\n",
        "    highest_flag = max(categories, key=lambda x: categories[x])\n",
        "\n",
        "    # Check if the content is flagged as inappropriate\n",
        "    if moderation.results[0].flagged:\n",
        "        # Get the highest flag\n",
        "        return True, highest_flag\n",
        "    else:\n",
        "        return False, None"
      ],
      "metadata": {
        "id": "K2cLOw2vsjCU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "def stitch_audio_segments(timestamps, input_file, output_file):\n",
        "    # Load the input audio file\n",
        "    audio = AudioSegment.from_file(input_file)\n",
        "\n",
        "    # Check if the output file already exists\n",
        "    if os.path.exists(output_file):\n",
        "        # Load the existing output audio file\n",
        "        stitched_audio = AudioSegment.from_file(output_file)\n",
        "    else:\n",
        "        # If the output file doesn't exist, create an empty audio segment\n",
        "        stitched_audio = AudioSegment.empty()\n",
        "\n",
        "    # Iterate over each (start, end) timestamp pair\n",
        "    for start, end in timestamps:\n",
        "        # Extract the audio segment based on timestamps\n",
        "        segment = audio[start*1000:end*1000]  # Convert timestamps to milliseconds\n",
        "\n",
        "        # Append the segment to the stitched audio\n",
        "        stitched_audio += segment\n",
        "\n",
        "    # Export the stitched audio to a new file\n",
        "    stitched_audio.export(output_file, format=\"wav\")"
      ],
      "metadata": {
        "id": "tZLUN0b4xRyV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "for x in m4a_files[3:]:\n",
        "    file_name = x\n",
        "    print(f\"file_name: {file_name}\")\n",
        "    input_file = path+file_name   # Provide your input audio file\n",
        "    print(f\"input_file: {input_file}\")\n",
        "    chunks_dir = path+file_name+\"-chunks/\"      # Provide the directory where chunks will be saved\n",
        "    print(f\"chunks_dir: {chunks_dir}\")\n",
        "    max_size_bytes = 26214400 # Maximum size of each chunk in bytes (e.g., 10 MB)\n",
        "    file_size = os.path.getsize(path+file_name)\n",
        "    print(f\"file_size: {file_size}\")\n",
        "    num_chunks = (int(file_size/max_size_bytes)+2)*4\n",
        "    print(f\"num_chunks: {num_chunks}\")\n",
        "    print()\n",
        "\n",
        "    output_file = path+'best-of-'+file_name\n",
        "\n",
        "    for chunk_file_name in os.listdir(chunks_dir):\n",
        "\n",
        "        # print(f\"{i} of {len(m4a_files)} m4a_files\")\n",
        "\n",
        "        audio_file = open(chunks_dir+chunk_file_name, \"rb\")\n",
        "\n",
        "        file_size = os.path.getsize(chunks_dir+chunk_file_name)\n",
        "\n",
        "        if file_size > 26214400:\n",
        "            print(f\"Too Big, file_name: {chunk_file_name}, file_size: {file_size}\")\n",
        "            # continue\n",
        "\n",
        "        transcript = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file,\n",
        "            response_format=\"verbose_json\",\n",
        "            timestamp_granularities=[\"segment\"]\n",
        "        )\n",
        "\n",
        "        # print(f\"Length of transcript: {len(transcript.text)}\")\n",
        "\n",
        "        duration = transcript.duration\n",
        "        segments = transcript.segments\n",
        "\n",
        "        flagged_segments = []\n",
        "\n",
        "        for segment in segments:\n",
        "            id = segment['id']\n",
        "            start = segment['start']\n",
        "            end = segment['end']\n",
        "            section = segment['text']\n",
        "            #print(f\"Start: {start}, End: {end}\")\n",
        "\n",
        "            section = re.sub(r'\\b(\\w+)\\s+\\1\\b', r'\\1', section)\n",
        "            section = re.sub(r'\\b(\\w+)\\s+\\1(?:\\s+\\1)+\\b', r'\\1', section)\n",
        "\n",
        "            judgement, flag = is_content_inappropriate(section)\n",
        "\n",
        "            if judgement:\n",
        "                flagged_segments.append(segment)\n",
        "                print(f\"Start: {start}, End: {end}\")\n",
        "                print(f\"FLAG: {flag}\")\n",
        "                print(section)\n",
        "                # print()\n",
        "\n",
        "        timestamps = []\n",
        "        for segment in flagged_segments:\n",
        "            timestamps.append((segment['start'],segment['end']))\n",
        "\n",
        "        input_file = path+file_name\n",
        "\n",
        "        stitch_audio_segments(timestamps, chunks_dir+chunk_file_name, output_file)"
      ],
      "metadata": {
        "id": "U9gf3JV-sHJA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
